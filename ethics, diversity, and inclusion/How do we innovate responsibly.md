[SFU Data Visionaries Fall 2018 - AJung Moon](https://www.youtube.com/watch?v=bpaexPaKBfU&ab_channel=SFU%27sBigDataHub)

## Talk Notes

Algorithmic ethics 
My Goal : To enable superheroes -> But with great power comes great responsibility.
‘When we create technology, we’re not creating tech just for ourselves. We’re actually facing a wider audience. 

Canadians:
Tech Believers (49%) vs Tech-Skeptics (51%)

Cambridge Analytica

For data and analytics we can’t ‘use code to abstract ourselves from consequences (and responsibility)’ 
Why? Because of decision making.
Why is algorithmic ethics important?
Accountability Gap

Manslaughter vs Murder - machines can’t be put in prison / punished, regardless of how much influence a machine might have on our lives, it’s always going to be humans who are responsible. 

If we’re designing algorithms that are influencing people’s decision making, such as election results and voting behaviour, then who should be held accountable?
Some people say ‘THE DESIGNERS’. Some designers say I’m just a scientist. I build stuff, I create this information / tools and then there are layers of businesses that take into account policies and how it’s used etc. 
This Gap in the ecosystem between businesses, leaders, users, designers, is the accountability gap. Who is indeed responsible? Who should take charge and make sure everything works well?
 


How is Algorithmic Ethics Different?
The applied Ethics gap
	• Research ethics: Harm; informed consent (eg. Does my subject know what they are getting into before consenting?)
	• Professional Ethics: Code of ethics of the profession (eg. IEEE ‘Welfare of the public’ as a core value); Corporate policies (eg. Don’t date your boss)
	• Algorithmic Ethics:
		○ What impact do algorithms have on individuals / society?
		○ How should we design our algorithms / systems?
		○ How do we ensure we make the right choices moving forward?

Subtleties - sometimes we delegate decisions to machines. 

Eg. The ‘Gaydar’ study -> Using deep learning, 80% of the time can identify if someone is homosexual.  This research was done to bring attention to the notion that this can be done and it’s kind of creepy and it doesn’t feel right to have these kinds of technologies out there [KIND OF SEEMS WEIRD THAT WE’D EVEN DO IT IN THE FIRST PLACE THEN]

ANYONE IN DATA SHOULD BE THINKING = ARE THERE ANY TRICKY ETHICAL Qs IN MY PROJECTS I OUGHT TO BE THINKING ABOUT??

What does this mean for data practitioners. These projects will be expected to have gone above and beyond the requirements of existing laws, and conduct due diligence, to protect the public from suffering negative consequences from the project. BUT HOW?[and it is happening eg. Policy and GDPR]
	1. WHAT ARE THE POTENTIAL IMPLICATIONS HERE?

We don’t necessarily have a clear framework to teach people on HOW to assess our impacts  

What are we doing about this?
- Algorithmic Impact Assessment (AIAs)
- Treasury Board Standard on Automated Decision Support Systems 
- Hippocratic oath for data scientists
- Call for audits and ethics roadmaps 

Some vocabulary for your own projects:
| ETHICAL RISK	| ETHICS ASSESSMENT |
|---------------|-------------------|
| Probability of ethical harm occurring from the frequency and severity of exposure to hazard	| Understanding of ethical risks associated with a project with the goal of creating a roadmap that helps manage the risks |
| Societal issues	| Transparency and interpretability : Do I know exactly what is happening. Can I understand what is happening? |
| Acceptance Issues	| Discrimination and fairness 
| Public Perception Issues	| Stakeholder perception, awareness, and trust
| Failure to Launch	| Privacy and security
| Commercial / Financial Loss	| Responsibility and Accountability
| Deterioration of work culture / environment	| Impact on Autonomy and jobs |
| Environmental issues | |
| Operational Issues | |
 ![image](https://user-images.githubusercontent.com/33766912/142478420-e4856fac-2e93-4617-845e-3d7146606438.png)
