# reading-list

Things I am reading 

## Privacy and Fairness

Title | Aims | Notes | Read?
--- | --- | --- | ---
[Privacy for All: Ensuring Fair and Equitable Privacy Protections](http://proceedings.mlr.press/v81/ekstrand18a/ekstrand18a.pdf) | Position Paper - applying recent research on ensuring socio-technical systems are fair and non-discriminatory to the privacy protections those systems may provide | Privacy systems may disproportionately fail to protect vulnerable members of the population. | <ul><li>- [x] read</li></ul>
[On the Compatibility of Privacy and Fairness](https://cpb-us-w2.wpmucdn.com/sites.gatech.edu/dist/c/679/files/2019/03/FairPrivate.pdf) | To see if both privacy and fairness can be achieved by one classifier or if tensions exist between the two | | <ul><li>- [x] read</li></ul>
[Fair Decision Making Using Privacy-Protected Data](https://arxiv.org/pdf/1905.12744.pdf) | To study the impact of formally private mechanisms on fair and equitable decision-making | Consider settings where sensitive personal data is used to decide who will recieve resources or benefits. | <ul><li>- [x] read</li></ul>
[Neither Private Nor Fair: Impact of Data Imbalance on Utility and Fairness in Differential Privacy](https://arxiv.org/pdf/2009.06389.pdf) | To study how different levels of imbalance in data affect the accuracy and fairness of decisions made by a model given different levels of privacy | Even small imbalances and loose privacy guarantees can cause disparate impacts | <ul><li>- [x] read</li></ul>
[Do the Machine Learning Models on a Crowd Sourced Platform Exhibit Bias? An Empirical Study on Model Fairness](https://arxiv.org/pdf/2005.12379.pdf) | To investigate the empirical evaluation of fairness and mitigation on real-world ML models | Some model optimization techniques result in inducing unfairness in the models. Although there are some fairness control mechanisms in ML libraries, they arenâ€™t documented. | <ul><li>- [ ] read</li></ul>
[SoK: Towards the Science of Security and Privacy in Machine Learning](https://arxiv.org/pdf/1611.03814.pdf) | | | <ul><li>- [ ] read</li></ul>
[Co-Designing Checklists to Understand Organisational Challenges and Opportunities around Fairness in AI](http://www.jennwv.com/papers/checklists.pdf) | | | <ul><li>- [ ] read</li></ul>
[AI FAIRNESS 360: AN EXTENSIBLE TOOLKIT FOR DETECTING, UNDERSTANDING, AND MITIGATING UNWANTED ALGORITHMIC BIAS](https://arxiv.org/pdf/1810.01943.pdf) | On AI Fairness 360 IBM | [A tool to measure fairness](https://aif360.mybluemix.net/) | <ul><li>- [ ] read</li></ul>
[Transparency Tools for Fairness in AI (Luskin)](https://arxiv.org/abs/2007.04484) | | | <ul><li>- [ ] read</li></ul>
[Delayed Impact of Fair Machine Learning](https://bair.berkeley.edu/blog/2018/05/17/delayed-impact/?source=post_page---------------------------) | | | <ul><li>- [ ] read</li></ul>

## Ocean Particle Clustering

Title | Aim | Notes | Read?
--- | --- | --- | ---
[Unsupervised Learning Reveals Geography of Global Ocean Dynamical Regions](https://agupubs.onlinelibrary.wiley.com/doi/full/10.1029/2018EA000519) | | | <ul><li>- [ ] read</li></ul>
[Unsupervised Clustering of Southern Ocean Argo Float Temperature Profiles](https://agupubs.onlinelibrary.wiley.com/doi/full/10.1029/2018JC014629) | | | <ul><li>- [ ] read</li></ul>
[Temporal changes in the causes of the observed oxygen decline in the St. Lawrence Estuary](https://agupubs.onlinelibrary.wiley.com/doi/abs/10.1029/2020JC016577) | To examine what has been contributing to the oxygen decline over the last five decades | | <ul><li>- [x] read</li></ul> 

## To Read
[Attention Is All You Need](https://arxiv.org/abs/1706.03762)
